# -*- coding: utf-8 -*-
"""
è¯­éŸ³æ´»åŠ¨æ£€æµ‹ (VAD) å¤„ç†å™¨
ä½¿ç”¨ WebRTC VAD è¿›è¡Œäººå£°æ£€æµ‹ï¼Œè¿‡æ»¤è½¦è½®å™ªéŸ³
"""
import logging
import time
from collections import deque
from typing import Optional, Tuple, List
from dataclasses import dataclass

# numpy æ˜¯å¯é€‰ä¾èµ–
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    np = None
    NUMPY_AVAILABLE = False

try:
    import webrtcvad
    WEBRTC_VAD_AVAILABLE = True
except ImportError:
    WEBRTC_VAD_AVAILABLE = False
    webrtcvad = None


@dataclass
class VADResult:
    """VAD æ£€æµ‹ç»“æœ"""
    is_speech: bool
    confidence: float  # 0.0 - 1.0
    speech_duration_ms: float
    silence_duration_ms: float


class VADProcessor:
    """
    è¯­éŸ³æ´»åŠ¨æ£€æµ‹å¤„ç†å™¨

    åŠŸèƒ½ï¼š
    1. æ£€æµ‹æ˜¯å¦ä¸ºäººå£°ï¼ˆè¿‡æ»¤è½¦è½®å™ªéŸ³ç­‰ç¯å¢ƒå™ªéŸ³ï¼‰
    2. æ£€æµ‹è¯´è¯å¼€å§‹å’Œç»“æŸ
    3. æä¾›è¿ç»­è¯­éŸ³/é™éŸ³æ—¶é•¿ç»Ÿè®¡
    """

    def __init__(
        self,
        aggressiveness: int = 2,
        frame_duration_ms: int = 30,
        min_speech_duration_ms: int = 300,
        min_silence_duration_ms: int = 500,
        logger: Optional[logging.Logger] = None
    ):
        """
        åˆå§‹åŒ– VAD å¤„ç†å™¨

        Args:
            aggressiveness: VAD æ•æ„Ÿåº¦ (0-3)
                0: æœ€æ•æ„Ÿï¼Œå®¹æ˜“æ£€æµ‹åˆ°è¯­éŸ³ï¼Œä½†å¯èƒ½è¯¯è§¦å‘
                1: è¾ƒæ•æ„Ÿ
                2: ä¸­ç­‰ï¼ˆæ¨èï¼‰
                3: æœ€ä¸æ•æ„Ÿï¼Œéœ€è¦å¤§å£°è¯´è¯
            frame_duration_ms: å¸§é•¿åº¦ï¼ˆæ¯«ç§’ï¼‰ï¼Œæ”¯æŒ 10, 20, 30
            min_speech_duration_ms: æœ€å°è¯­éŸ³é•¿åº¦ï¼ŒçŸ­äºæ­¤é•¿åº¦è®¤ä¸ºæ˜¯å™ªéŸ³
            min_silence_duration_ms: æœ€å°é™éŸ³é•¿åº¦ï¼Œç”¨äºåˆ¤æ–­è¯´è¯ç»“æŸ
        """
        if not WEBRTC_VAD_AVAILABLE:
            raise ImportError("webrtcvad æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install webrtcvad")

        self.logger = logger or logging.getLogger(__name__)

        # VAD å‚æ•°
        self.aggressiveness = max(0, min(3, aggressiveness))
        self.frame_duration_ms = frame_duration_ms
        self.min_speech_duration_ms = min_speech_duration_ms
        self.min_silence_duration_ms = min_silence_duration_ms

        # åˆ›å»º VAD å¯¹è±¡
        self.vad = webrtcvad.Vad(aggressiveness)
        self.frame_size = int(self.frame_duration_ms * 16)  # 16kHz é‡‡æ ·ç‡

        # çŠ¶æ€è·Ÿè¸ª
        self.is_speaking = False
        self.speech_start_time: Optional[float] = None
        self.silence_start_time: Optional[float] = None

        # ç»Ÿè®¡æ•°æ®
        self.speech_frames = 0
        self.silence_frames = 0
        self.total_frames = 0

        # å†å²æ•°æ®ï¼ˆç”¨äºå¹³æ»‘ï¼‰
        self.recent_results = deque(maxlen=5)  # ä¿å­˜æœ€è¿‘ 5 å¸§çš„ç»“æœ

        self.logger.info(f"VAD åˆå§‹åŒ–: æ•æ„Ÿåº¦={self.aggressiveness}, å¸§é•¿={self.frame_duration_ms}ms")

    def process_frame(self, audio_data: bytes) -> VADResult:
        """
        å¤„ç†ä¸€å¸§éŸ³é¢‘æ•°æ®

        Args:
            audio_data: éŸ³é¢‘æ•°æ® (bytes)ï¼Œå¿…é¡»æ˜¯æ­£ç¡®çš„å¸§é•¿åº¦

        Returns:
            VADResult: VAD æ£€æµ‹ç»“æœ
        """
        # æ£€æŸ¥å¸§é•¿åº¦
        if len(audio_data) != self.frame_size * 2:  # 16-bit = 2 bytes
            self.logger.warning(f"éŸ³é¢‘å¸§é•¿åº¦ä¸æ­£ç¡®: æœŸæœ› {self.frame_size * 2}, å®é™… {len(audio_data)}")
            return VADResult(is_speech=False, confidence=0.0,
                           speech_duration_ms=0.0, silence_duration_ms=0.0)

        # ä½¿ç”¨ VAD æ£€æµ‹
        is_speech = self.vad.is_speech(audio_data, self.sample_rate)

        # æ›´æ–°ç»Ÿè®¡
        self.total_frames += 1
        if is_speech:
            self.speech_frames += 1
        else:
            self.silence_frames += 1

        # å¹³æ»‘å¤„ç†ï¼ˆåŸºäºå†å²ç»“æœï¼‰
        self.recent_results.append(is_speech)
        smoothed_speech = self.smooth_results()

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = self.calculate_confidence()

        # æ›´æ–°çŠ¶æ€
        current_time = time.time()
        speech_duration = 0.0
        silence_duration = 0.0

        if smoothed_speech:
            if not self.is_speaking:
                # æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                self.speech_start_time = current_time
                self.is_speaking = True
                self.logger.debug("æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹")

            speech_duration = (current_time - self.speech_start_time) * 1000 if self.speech_start_time else 0
            self.silence_start_time = None
        else:
            if self.is_speaking:
                # æ£€æµ‹åˆ°é™éŸ³
                if self.silence_start_time is None:
                    self.silence_start_time = current_time

                silence_duration = (current_time - self.silence_start_time) * 1000

                # å¦‚æœé™éŸ³æ—¶é—´è¶³å¤Ÿé•¿ï¼Œè®¤ä¸ºè¯´è¯ç»“æŸ
                if silence_duration >= self.min_silence_duration_ms:
                    speech_duration = (self.silence_start_time - self.speech_start_time) * 1000 if self.speech_start_time else 0

                    # åªæœ‰è¿‡è¶³å¤Ÿé•¿çš„è¯­éŸ³æ‰ç®—æœ‰æ•ˆ
                    if speech_duration >= self.min_speech_duration_ms:
                        self.logger.debug(f"æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼ŒæŒç»­ {speech_duration:.0f}ms")
                    else:
                        self.logger.debug(f"å¿½ç•¥çŸ­è¯­éŸ³ ({speech_duration:.0f}ms < {self.min_speech_duration_ms}ms)")

                    self.is_speaking = False
                    self.speech_start_time = None

        return VADResult(
            is_speech=smoothed_speech,
            confidence=confidence,
            speech_duration_ms=speech_duration,
            silence_duration_ms=silence_duration
        )

    @property
    def sample_rate(self) -> int:
        """é‡‡æ ·ç‡"""
        return 16000

    def smooth_results(self) -> bool:
        """
        å¹³æ»‘ VAD ç»“æœï¼ˆåŸºäºå†å²å¸§ï¼‰
        å¦‚æœæœ€è¿‘çš„å¸§ä¸­å¤§å¤šæ•°æ˜¯è¯­éŸ³ï¼Œåˆ™è®¤ä¸ºæ˜¯è¯­éŸ³
        """
        if not self.recent_results:
            return False

        speech_count = sum(1 for r in self.recent_results if r)
        return speech_count > len(self.recent_results) // 2

    def calculate_confidence(self) -> float:
        """
        è®¡ç®—ç½®ä¿¡åº¦
        åŸºäºæœ€è¿‘çš„è¯­éŸ³å¸§æ¯”ä¾‹
        """
        if not self.recent_results:
            return 0.0

        speech_ratio = sum(1 for r in self.recent_results if r) / len(self.recent_results)
        return speech_ratio

    def reset(self):
        """é‡ç½® VAD çŠ¶æ€"""
        self.is_speaking = False
        self.speech_start_time = None
        self.silence_start_time = None
        self.speech_frames = 0
        self.silence_frames = 0
        self.total_frames = 0
        self.recent_results.clear()
        self.logger.debug("VAD çŠ¶æ€å·²é‡ç½®")

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        speech_ratio = self.speech_frames / self.total_frames if self.total_frames > 0 else 0
        return {
            "total_frames": self.total_frames,
            "speech_frames": self.speech_frames,
            "silence_frames": self.silence_frames,
            "speech_ratio": speech_ratio,
            "is_speaking": self.is_speaking
        }

    def should_trigger_asr(self) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘ ASR è¯†åˆ«

        æ¡ä»¶ï¼š
        1. æ£€æµ‹åˆ°è¶³å¤Ÿé•¿çš„è¯­éŸ³ï¼ˆè¶…è¿‡ min_speech_duration_msï¼‰
        2. æ£€æµ‹åˆ°è¶³å¤Ÿé•¿çš„é™éŸ³ï¼ˆè¶…è¿‡ min_silence_duration_msï¼‰
        """
        return (
            not self.is_speaking and
            self.speech_start_time is not None and
            self.silence_start_time is not None
        )


class NoiseFilter:
    """
    å™ªéŸ³è¿‡æ»¤å™¨

    åŠŸèƒ½ï¼š
    1. åŸºäºèƒ½é‡é˜ˆå€¼è¿‡æ»¤ä½èƒ½é‡å™ªéŸ³
    2. åŸºäºé¢‘è°±åˆ†æè¯†åˆ«ç”µæœºå™ªéŸ³ç‰¹å¾
    """

    def __init__(
        self,
        energy_threshold: float = 0.01,
        logger: Optional[logging.Logger] = None
    ):
        """
        åˆå§‹åŒ–å™ªéŸ³è¿‡æ»¤å™¨

        Args:
            energy_threshold: èƒ½é‡é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è®¤ä¸ºæ˜¯å™ªéŸ³
        """
        self.logger = logger or logging.getLogger(__name__)
        self.energy_threshold = energy_threshold

        # è‡ªé€‚åº”é˜ˆå€¼
        self.noise_floor = 0.0
        self.adaptation_rate = 0.1

    def is_noise(self, audio_data) -> bool:
        """
        åˆ¤æ–­éŸ³é¢‘æ˜¯å¦ä¸ºå™ªéŸ³

        Args:
            audio_data: éŸ³é¢‘æ•°æ® (å½’ä¸€åŒ–åˆ° [-1, 1])ï¼Œæ”¯æŒ numpy æ•°ç»„æˆ–åˆ—è¡¨

        Returns:
            True å¦‚æœæ˜¯å™ªéŸ³ï¼ŒFalse å¦‚æœæ˜¯æœ‰æ•ˆè¯­éŸ³
        """
        # å…¼å®¹ numpy å’ŒåŸç”Ÿ Python
        if NUMPY_AVAILABLE and np is not None and hasattr(audio_data, '__array__'):
            # ä½¿ç”¨ numpy åŠ é€Ÿ
            energy = float(np.mean(audio_data ** 2))

            # é¢‘è°±åˆ†æï¼ˆç®€å•çš„è¿‡é›¶ç‡ï¼‰
            zero_crossing_rate = float(np.mean(np.diff(np.sign(audio_data)) != 0))
        else:
            # ä½¿ç”¨çº¯ Python å®ç°
            energy = sum(x * x for x in audio_data) / len(audio_data)

            # è®¡ç®—è¿‡é›¶ç‡
            sign_changes = sum(1 for i in range(1, len(audio_data))
                             if (audio_data[i] >= 0) != (audio_data[i-1] >= 0))
            zero_crossing_rate = sign_changes / len(audio_data)

        # æ›´æ–°å™ªéŸ³åº•å™ªä¼°è®¡
        if energy < self.noise_floor:
            self.noise_floor = self.noise_floor * (1 - self.adaptation_rate) + energy * self.adaptation_rate
        elif energy < self.noise_floor * 2:
            self.noise_floor = self.noise_floor * (1 - self.adaptation_rate * 0.5) + energy * (self.adaptation_rate * 0.5)

        # åˆ¤æ–­æ˜¯å¦ä½äºèƒ½é‡é˜ˆå€¼
        is_below_threshold = energy < max(self.energy_threshold, self.noise_floor * 3)

        # ç”µæœºå™ªéŸ³é€šå¸¸æœ‰è¾ƒä½çš„è¿‡é›¶ç‡å’ŒæŒç»­çš„èƒ½é‡
        is_motor_noise = (energy > self.noise_floor * 2) and (zero_crossing_rate < 0.1)

        return is_below_threshold or is_motor_noise

    def get_noise_floor(self) -> float:
        """è·å–å½“å‰å™ªéŸ³åº•å™ªä¼°è®¡"""
        return self.noise_floor


def test_vad():
    """æµ‹è¯• VAD åŠŸèƒ½"""
    import sys
    from pvrecorder import PvRecorder

    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    if not WEBRTC_VAD_AVAILABLE:
        print("é”™è¯¯: webrtcvad æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install webrtcvad")
        return

    print("VAD æµ‹è¯•ç¨‹åº")
    print("=" * 50)

    # åˆ—å‡ºéº¦å…‹é£
    devices = PvRecorder.get_available_devices()
    for i, dev in enumerate(devices):
        print(f"[{i}] {dev}")

    try:
        mic_index = int(input("\né€‰æ‹©éº¦å…‹é£ç´¢å¼•: "))
    except ValueError:
        mic_index = -1

    # åˆå§‹åŒ–
    vad = VADProcessor(
        aggressiveness=2,
        frame_duration_ms=30,
        min_speech_duration_ms=300,
        min_silence_duration_ms=500
    )
    noise_filter = NoiseFilter(energy_threshold=0.01)

    # å¯åŠ¨éº¦å…‹é£
    recorder = PvRecorder(device_index=mic_index, frame_length=512)  # 512 samples = 32ms @ 16kHz
    recorder.start()

    print("\nå¼€å§‹ç›‘å¬... è¯´è¯æ—¶è§‚å¯Ÿè¾“å‡º")
    print("æŒ‰ Ctrl+C é€€å‡º\n")

    try:
        speech_buffer = []

        while True:
            pcm = recorder.read()

            # è½¬æ¢ä¸ºéœ€è¦çš„å¸§é•¿åº¦
            frame_size = int(30 * 16)  # 30ms @ 16kHz
            for i in range(0, len(pcm), frame_size * 2):
                frame_bytes = bytes(pcm[i:i + frame_size * 2])

                if len(frame_bytes) < frame_size * 2:
                    break

                # VAD æ£€æµ‹
                result = vad.process_frame(frame_bytes)

                # å™ªéŸ³è¿‡æ»¤
                audio_array = np.frombuffer(frame_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                is_noise = noise_filter.is_noise(audio_array)

                # è¾“å‡ºç»“æœ
                if result.is_speech and not is_noise:
                    speech_buffer.append(frame_bytes)
                    print("ğŸ¤ ", end="", flush=True)
                else:
                    if speech_buffer:
                        duration = len(speech_buffer) * 30
                        if duration >= vad.min_speech_duration_ms:
                            print(f"\nâœ… æ£€æµ‹åˆ°è¯­éŸ³ï¼ŒæŒç»­ {duration}ms")
                        speech_buffer.clear()

                    if is_noise:
                        print("ğŸ”‡", end="", flush=True)
                    else:
                        print(".", end="", flush=True)

    except KeyboardInterrupt:
        print("\n\nç»Ÿè®¡ä¿¡æ¯:")
        stats = vad.get_stats()
        print(f"  æ€»å¸§æ•°: {stats['total_frames']}")
        print(f"  è¯­éŸ³å¸§: {stats['speech_frames']} ({stats['speech_ratio']*100:.1f}%)")
        print(f"  é™éŸ³å¸§: {stats['silence_frames']}")
        print(f"  å™ªéŸ³åº•å™ª: {noise_filter.get_noise_floor():.6f}")

    finally:
        recorder.stop()
        recorder.delete()


if __name__ == "__main__":
    test_vad()
